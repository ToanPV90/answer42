# 9.5 Multi-Agent Pipeline Architecture

## Overview

The Answer42 multi-agent pipeline architecture implements a sophisticated orchestrator-based pattern for processing academic papers. This architecture ensures scalable, reliable, and maintainable AI-powered analysis through specialized agents that work in coordination to deliver comprehensive paper insights.

## Architecture Principles

### 1. Separation of Concerns

Each agent has a specific, well-defined responsibility:

- **Single Responsibility**: Each agent performs one primary function
- **Interface Consistency**: All agents implement the same base interface
- **Data Isolation**: Agents operate on their own data domains
- **Error Isolation**: Failures in one agent don't cascade to others

### 2. Orchestrator Pattern

The central orchestrator coordinates all agent activities:

- **Central Control**: Single point of workflow management
- **Dynamic Routing**: Routes tasks based on content and requirements
- **State Management**: Tracks pipeline progress and intermediate results
- **Resource Allocation**: Manages AI provider API usage and rate limits

### 3. Asynchronous Processing

All pipeline operations execute asynchronously:

- **Non-blocking Operations**: UI remains responsive during processing
- **Parallel Execution**: Independent agents can run concurrently
- **Background Processing**: Long-running tasks don't block user interactions
- **Progress Tracking**: Real-time updates to user interface

## Core Components

### Pipeline Orchestrator

```java
@Service
@Transactional
public class PipelineOrchestrator {
    private final Map<AgentType, AIAgent> agents = new ConcurrentHashMap<>();
    private final Executor taskExecutor; // From ThreadConfig
    private final ThreadPoolTaskScheduler taskScheduler; // From ThreadConfig
    private final PipelineStateManager stateManager;
    private final AIConfig aiConfig; // Integration with existing AIConfig

    public PipelineOrchestrator(
            ThreadConfig threadConfig,
            AIConfig aiConfig,
            PipelineStateManager stateManager) {
        this.taskExecutor = threadConfig.taskExecutor();
        this.taskScheduler = threadConfig.taskScheduler();
        this.aiConfig = aiConfig;
        this.stateManager = stateManager;
    }

    /**
     * Executes the complete paper processing pipeline using ThreadConfig executor
     */
    @Async("taskExecutor") // Uses ThreadConfig's taskExecutor bean
    public CompletableFuture<PipelineResult> processPaper(
            UUID paperId, 
            PipelineConfiguration config,
            ProgressCallback progressCallback) {

        LoggingUtil.info(LOG, "processPaper", 
            "Starting pipeline for paper %s with config %s", paperId, config);

        try {
            // Initialize pipeline state
            PipelineState state = stateManager.initializePipeline(paperId, config);

            // Create execution plan using AIConfig providers
            ExecutionPlan plan = createExecutionPlan(config);

            // Execute pipeline stages with ThreadConfig executor
            return executeStages(state, plan, progressCallback);

        } catch (Exception e) {
            LoggingUtil.error(LOG, "processPaper", 
                "Failed to start pipeline for paper %s", e, paperId);
            throw new PipelineException("Pipeline initialization failed", e);
        }
    }

    private ExecutionPlan createExecutionPlan(PipelineConfiguration config) {
        ExecutionPlan.Builder builder = ExecutionPlan.builder();

        // Stage 1: Text Extraction (Required)
        builder.addStage(StageType.TEXT_EXTRACTION, AgentType.PAPER_PROCESSOR);

        // Stage 2: Metadata Enhancement (Parallel)
        if (config.includeMetadataEnhancement()) {
            builder.addParallelStage(StageType.METADATA_ENHANCEMENT, 
                Arrays.asList(AgentType.CROSSREF_AGENT, AgentType.SEMANTIC_SCHOLAR_AGENT));
        }

        // Stage 3: Content Analysis (Sequential)
        builder.addStage(StageType.SECTION_IDENTIFICATION, AgentType.STRUCTURE_ANALYZER);
        builder.addStage(StageType.CONCEPT_EXTRACTION, AgentType.CONCEPT_EXTRACTOR);

        // Stage 4: Summary Generation (Conditional)
        if (config.generateSummaries()) {
            builder.addStage(StageType.SUMMARY_GENERATION, AgentType.CONTENT_SUMMARIZER);
        }

        // Stage 5: Quality Verification (Always last)
        builder.addStage(StageType.QUALITY_CHECK, AgentType.QUALITY_CHECKER);

        return builder.build();
    }
}
```

### Agent Base Interface

```java
public interface AIAgent {
    /**
     * Unique identifier for this agent type
     */
    AgentType getAgentType();

    /**
     * AI provider this agent uses
     */
    AIProvider getProvider();

    /**
     * Process the given task and return results
     */
    CompletableFuture<AgentResult> process(AgentTask task);

    /**
     * Validate that this agent can handle the given task
     */
    boolean canHandle(AgentTask task);

    /**
     * Get estimated processing time for the task
     */
    Duration estimateProcessingTime(AgentTask task);

    /**
     * Get current load/capacity status
     */
    LoadStatus getLoadStatus();
}
```

### Pipeline State Management

```java
@Component
public class PipelineStateManager {
    private final Map<UUID, PipelineState> activePipelines = new ConcurrentHashMap<>();
    private final PipelineStateRepository stateRepository;

    public PipelineState initializePipeline(UUID paperId, PipelineConfiguration config) {
        PipelineState state = PipelineState.builder()
            .id(UUID.randomUUID())
            .paperId(paperId)
            .configuration(config)
            .status(PipelineStatus.INITIALIZING)
            .startTime(LocalDateTime.now())
            .stages(initializeStages(config))
            .build();

        activePipelines.put(state.getId(), state);
        stateRepository.save(state);

        return state;
    }

    public void updateStageStatus(UUID pipelineId, StageType stage, StageStatus status) {
        PipelineState state = activePipelines.get(pipelineId);
        if (state != null) {
            state.updateStage(stage, status);
            stateRepository.save(state);

            // Notify progress listeners
            notifyProgressListeners(state);
        }
    }

    private void notifyProgressListeners(PipelineState state) {
        double progress = calculateProgress(state);

        // Update UI through WebSocket or similar mechanism
        messagingTemplate.convertAndSend(
            "/topic/pipeline/" + state.getPaperId(),
            new PipelineProgressUpdate(state.getId(), progress, state.getCurrentStage())
        );
    }
}
```

## Execution Flow

### Sequential Processing

For tasks that must complete in order:

```java
public CompletableFuture<StageResult> executeSequentialStages(
        List<StageDefinition> stages, 
        PipelineContext context) {

    CompletableFuture<StageResult> result = CompletableFuture.completedFuture(null);

    for (StageDefinition stage : stages) {
        result = result.thenCompose(previousResult -> {
            // Update context with previous results
            if (previousResult != null) {
                context.addResult(stage.getPreviousStage(), previousResult);
            }

            // Execute current stage
            AIAgent agent = agents.get(stage.getAgentType());
            AgentTask task = createAgentTask(stage, context);

            return agent.process(task)
                .thenApply(agentResult -> convertToStageResult(stage, agentResult));
        });
    }

    return result;
}
```

### Parallel Processing

For independent tasks that can run concurrently:

```java
public CompletableFuture<List<StageResult>> executeParallelStages(
        List<StageDefinition> stages, 
        PipelineContext context) {

    List<CompletableFuture<StageResult>> futures = stages.stream()
        .map(stage -> {
            AIAgent agent = agents.get(stage.getAgentType());
            AgentTask task = createAgentTask(stage, context);

            return agent.process(task)
                .thenApply(agentResult -> convertToStageResult(stage, agentResult));
        })
        .collect(Collectors.toList());

    return CompletableFuture.allOf(futures.toArray(new CompletableFuture[0]))
        .thenApply(v -> futures.stream()
            .map(CompletableFuture::join)
            .collect(Collectors.toList()));
}
```

## Error Handling Strategy

### Circuit Breaker Pattern

Prevents cascade failures when agents become unavailable:

```java
@Component
public class AgentCircuitBreaker {
    private final Map<AgentType, CircuitBreakerState> circuitStates = new ConcurrentHashMap<>();

    public <T> CompletableFuture<T> executeWithCircuitBreaker(
            AgentType agentType, 
            Supplier<CompletableFuture<T>> operation) {

        CircuitBreakerState state = circuitStates.get(agentType);

        if (state.isOpen()) {
            LoggingUtil.warn(LOG, "executeWithCircuitBreaker", 
                "Circuit breaker is OPEN for agent %s", agentType);
            return CompletableFuture.failedFuture(
                new CircuitBreakerOpenException("Agent " + agentType + " is unavailable"));
        }

        return operation.get()
            .whenComplete((result, throwable) -> {
                if (throwable != null) {
                    state.recordFailure();
                } else {
                    state.recordSuccess();
                }
            });
    }
}
```

### Retry Mechanism

Handles transient failures with exponential backoff:

```java
public class AgentRetryPolicy {
    private static final int MAX_RETRIES = 3;
    private static final Duration INITIAL_DELAY = Duration.ofSeconds(1);

    public <T> CompletableFuture<T> executeWithRetry(
            Supplier<CompletableFuture<T>> operation) {

        return executeWithRetry(operation, 0);
    }

    private <T> CompletableFuture<T> executeWithRetry(
            Supplier<CompletableFuture<T>> operation, 
            int attemptNumber) {

        return operation.get()
            .exceptionallyCompose(throwable -> {
                if (attemptNumber >= MAX_RETRIES || !isRetryableException(throwable)) {
                    return CompletableFuture.failedFuture(throwable);
                }

                Duration delay = INITIAL_DELAY.multipliedBy((long) Math.pow(2, attemptNumber));

                LoggingUtil.warn(LOG, "executeWithRetry", 
                    "Retrying operation after %dms (attempt %d/%d)", 
                    delay.toMillis(), attemptNumber + 1, MAX_RETRIES);

                return CompletableFuture.delayedExecutor(delay.toMillis(), TimeUnit.MILLISECONDS)
                    .execute(() -> executeWithRetry(operation, attemptNumber + 1));
            });
    }
}
```

## Resource Management

### Rate Limiting

Manages API usage across providers:

```java
@Component
public class APIRateLimiter {
    private final Map<AIProvider, RateLimiter> rateLimiters = new ConcurrentHashMap<>();

    public CompletableFuture<Void> acquirePermit(AIProvider provider) {
        RateLimiter limiter = rateLimiters.get(provider);

        if (limiter.tryAcquire()) {
            return CompletableFuture.completedFuture(null);
        }

        // Wait for permit to become available
        return CompletableFuture.supplyAsync(() -> {
            limiter.acquire();
            return null;
        });
    }
}
```

### Memory Management

Prevents memory leaks during long-running pipelines:

```java
public class PipelineMemoryManager {
    private final Map<UUID, WeakReference<PipelineContext>> contextCache = new ConcurrentHashMap<>();

    public void registerPipeline(UUID pipelineId, PipelineContext context) {
        contextCache.put(pipelineId, new WeakReference<>(context));

        // Schedule cleanup
        scheduler.schedule(() -> cleanup(pipelineId), 1, TimeUnit.HOURS);
    }

    private void cleanup(UUID pipelineId) {
        WeakReference<PipelineContext> ref = contextCache.remove(pipelineId);
        if (ref != null) {
            PipelineContext context = ref.get();
            if (context != null) {
                context.cleanup();
            }
        }
    }
}
```

## Monitoring and Observability

### Metrics Collection

Tracks pipeline performance and health:

```java
@Component
public class PipelineMetrics {
    private final MeterRegistry meterRegistry;
    private final Counter pipelineStarted;
    private final Counter pipelineCompleted;
    private final Timer pipelineExecutionTime;

    public void recordPipelineStart(PipelineConfiguration config) {
        pipelineStarted.increment(
            Tags.of(
                "config_type", config.getType().name(),
                "agent_count", String.valueOf(config.getRequiredAgents().size())
            )
        );
    }

    public void recordPipelineCompletion(UUID pipelineId, Duration executionTime) {
        pipelineCompleted.increment();
        pipelineExecutionTime.record(executionTime);

        LoggingUtil.info(LOG, "recordPipelineCompletion", 
            "Pipeline %s completed in %dms", pipelineId, executionTime.toMillis());
    }
}
```

### Health Checks

Monitors agent availability and performance:

```java
@Component
public class AgentHealthMonitor {

    @Scheduled(fixedRate = 30000) // Every 30 seconds
    public void checkAgentHealth() {
        agents.values().parallelStream().forEach(agent -> {
            try {
                HealthCheckResult result = performHealthCheck(agent);
                updateAgentStatus(agent.getAgentType(), result);

            } catch (Exception e) {
                LoggingUtil.error(LOG, "checkAgentHealth", 
                    "Health check failed for agent %s", e, agent.getAgentType());
                markAgentUnhealthy(agent.getAgentType());
            }
        });
    }
}
```

## Configuration and Customization

### Pipeline Templates

Pre-defined configurations for common use cases:

```java
public enum PipelineTemplate {
    QUICK_ANALYSIS(
        Set.of(AgentType.PAPER_PROCESSOR, AgentType.CONTENT_SUMMARIZER),
        Duration.ofMinutes(2)
    ),

    COMPREHENSIVE_ANALYSIS(
        Set.of(AgentType.PAPER_PROCESSOR, AgentType.METADATA_ENHANCER, 
               AgentType.CONTENT_SUMMARIZER, AgentType.CONCEPT_EXTRACTOR,
               AgentType.CITATION_ANALYZER, AgentType.QUALITY_CHECKER),
        Duration.ofMinutes(10)
    ),

    RESEARCH_GRADE(
        Set.of(AgentType.PAPER_PROCESSOR, AgentType.METADATA_ENHANCER,
               AgentType.CONTENT_SUMMARIZER, AgentType.CONCEPT_EXTRACTOR,
               AgentType.CITATION_ANALYZER, AgentType.QUALITY_CHECKER,
               AgentType.EXTERNAL_VERIFIER, AgentType.ACADEMIC_VALIDATOR),
        Duration.ofMinutes(15)
    );
}
```

This architecture provides a robust, scalable foundation for the Answer42 multi-agent pipeline, ensuring reliable paper processing while maintaining flexibility for future enhancements and customizations.
