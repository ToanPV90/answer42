# 9.7.3 Cost Tracking and Results Integration

## Overview

This document details how the multi-agent pipeline integrates with Answer42's existing cost tracking system, token counting, and results storage. The pipeline leverages existing tables: `operation_costs`, `user_operations`, `credit_balances`, `credit_transactions`, and stores results in the `papers` table JSONB fields.

## Current Database Schema Analysis

### Existing Cost Structure

From the `operation_costs` table, we have 20 existing operations with tiered pricing:

```sql
-- Current operation types in operation_costs table
PAPER_UPLOAD                    -- 5/8/10 credits
GENERATE_SUMMARY               -- 2/4/6 credits  
CONCEPT_EXPLANATION            -- 3/5/7 credits
STUDY_GUIDE_CREATION           -- 5/8/10 credits
QA_SESSION                     -- 5/7/9 credits
PERPLEXITY_QUERY              -- 3/5/7 credits
CROSS_REFERENCE_CHAT          -- 5/8/12 credits
PAPER_CHAT                    -- 3/5/7 credits
RESEARCH_EXPLORER_CHAT        -- 5/7/10 credits
DEEP_SUMMARY                  -- 5/8/10 credits
METHODOLOGY_ANALYSIS          -- 6/9/12 credits
RESULTS_INTERPRETATION        -- 6/9/12 credits
CRITICAL_EVALUATION           -- 7/10/14 credits
RESEARCH_IMPLICATIONS         -- 5/8/10 credits
-- Plus visualization operations...
```

### Paper Results Storage Schema

The `papers` table contains multiple JSONB fields for storing agent results:

```sql
-- Agent processing results stored in papers table
text_content                  VARCHAR    -- Extracted text
summary_brief                VARCHAR    -- Brief summary
summary_standard             VARCHAR    -- Standard summary  
summary_detailed             VARCHAR    -- Detailed summary
key_findings                 JSONB      -- Key findings
methodology_details          JSONB      -- Methodology analysis
quality_feedback            JSONB      -- Quality assessment
citations                   JSONB      -- Citation data
glossary                    JSONB      -- Term definitions
main_concepts               JSONB      -- Core concepts
research_questions          JSONB      -- Research questions
topics                      JSONB      -- Topic classification
metadata                    JSONB      -- General metadata
crossref_metadata           JSONB      -- Crossref API data
semantic_scholar_metadata   JSONB      -- Semantic Scholar data
processing_status           VARCHAR    -- Current processing status
status                      VARCHAR    -- General status
```

## ✅ Database Schema Implementation (COMPLETED)

### Database Compliance Verification

**✅ operation_costs.operation_type**: Uses enum `operation_type_upper` (enforces UPPERCASE)
**✅ user_operations.operation_type**: Uses text type (supports UPPERCASE, no restrictions)

### ✅ Multi-Agent Operation Types (SUCCESSFULLY ADDED)

The following operation types have been successfully added to the database:

```sql
-- ✅ COMPLETED: Multi-agent operation types added to operation_costs table
PAPER_TEXT_EXTRACTION        -- 3/5/7 credits   (✓ Added)
METADATA_ENHANCEMENT         -- 2/3/4 credits   (✓ Added)
CONTENT_SUMMARIZATION        -- 4/6/8 credits   (✓ Added)
QUALITY_CHECKING             -- 4/6/8 credits   (✓ Added)
CITATION_FORMATTING          -- 2/3/4 credits   (✓ Added)
RESEARCH_DISCOVERY           -- 5/7/10 credits  (✓ Added)
FULL_PIPELINE_PROCESSING     -- 15/22/30 credits (✓ Added)
TOKEN_USAGE_TRACKING         -- 0/0/0 credits   (✓ Added)
```

**Database Updates Completed:**
1. ✅ Added 8 new operation types to `operation_type_upper` enum
2. ✅ Inserted corresponding cost records with Basic/Pro/Scholar pricing
3. ✅ All operation types properly uppercase as required
4. ✅ Database schema fully compliant with existing structure

## Token Counting Integration

### Token Tracking Service

```java
@Service
@Transactional
public class TokenTrackingService {
    
    private final UserOperationRepository userOperationRepository;
    private final CreditService creditService;
    private final Logger logger = LoggerFactory.getLogger(TokenTrackingService.class);
    
    public TokenTrackingService(
            UserOperationRepository userOperationRepository,
            CreditService creditService) {
        this.userOperationRepository = userOperationRepository;
        this.creditService = creditService;
    }
    
    /**
     * Track token usage for an agent operation.
     */
    public void trackTokenUsage(UUID userId, String operationType, String agentType, 
                               TokenUsage tokenUsage, String referenceId) {
        
        try {
            // Calculate cost based on token usage and operation type
            int calculatedCost = calculateTokenBasedCost(operationType, tokenUsage);
            
            // Create user operation record
            UserOperation operation = new UserOperation();
            operation.setUserId(userId);
            operation.setOperationType(operationType);
            operation.setReferenceId(referenceId);
            operation.setCreditCost(calculatedCost);
            
            // Store token details in metadata
            Map<String, Object> metadata = new HashMap<>();
            metadata.put("agentType", agentType);
            metadata.put("inputTokens", tokenUsage.getPromptTokens());
            metadata.put("outputTokens", tokenUsage.getGenerationTokens());
            metadata.put("totalTokens", tokenUsage.getTotalTokens());
            metadata.put("model", tokenUsage.getModel());
            metadata.put("provider", tokenUsage.getProvider());
            metadata.put("processingTime", tokenUsage.getProcessingTime());
            metadata.put("timestamp", Instant.now().toString());
            
            operation.setMetadata(JsonNodeFactory.instance.valueToTree(metadata));
            
            userOperationRepository.save(operation);
            
            logger.info("Tracked token usage for user {}: {} tokens, {} credits, operation {}", 
                       userId, tokenUsage.getTotalTokens(), calculatedCost, operationType);
            
        } catch (Exception e) {
            logger.error("Failed to track token usage for user {}: {}", userId, e.getMessage(), e);
        }
    }
    
    /**
     * Calculate cost based on token usage and operation complexity.
     */
    private int calculateTokenBasedCost(String operationType, TokenUsage tokenUsage) {
        // Base cost from operation_costs table
        int baseCost = getBaseCostForOperation(operationType);
        
        // Token-based multiplier for large operations
        int totalTokens = tokenUsage.getTotalTokens();
        double tokenMultiplier = 1.0;
        
        if (totalTokens > 100000) {
            tokenMultiplier = 2.0; // Double cost for very large operations
        } else if (totalTokens > 50000) {
            tokenMultiplier = 1.5; // 50% increase for large operations
        } else if (totalTokens > 20000) {
            tokenMultiplier = 1.25; // 25% increase for medium operations
        }
        
        return (int) Math.ceil(baseCost * tokenMultiplier);
    }
    
    /**
     * Get aggregated token usage statistics for a user.
     */
    public TokenUsageStatistics getUserTokenStatistics(UUID userId, LocalDateTime since) {
        List<UserOperation> operations = userOperationRepository
            .findByUserIdAndCreatedAtAfter(userId, since);
        
        long totalTokens = 0;
        long totalCredits = 0;
        Map<String, Long> tokensByProvider = new HashMap<>();
        Map<String, Long> tokensByAgent = new HashMap<>();
        
        for (UserOperation op : operations) {
            JsonNode metadata = op.getMetadata();
            if (metadata != null && metadata.has("totalTokens")) {
                long tokens = metadata.get("totalTokens").asLong();
                totalTokens += tokens;
                
                String provider = metadata.has("provider") ? metadata.get("provider").asText() : "unknown";
                String agent = metadata.has("agentType") ? metadata.get("agentType").asText() : "unknown";
                
                tokensByProvider.merge(provider, tokens, Long::sum);
                tokensByAgent.merge(agent, tokens, Long::sum);
            }
            
            if (op.getCreditCost() != null) {
                totalCredits += op.getCreditCost();
            }
        }
        
        return TokenUsageStatistics.builder()
            .userId(userId)
            .period(since)
            .totalTokens(totalTokens)
            .totalCredits(totalCredits)
            .tokensByProvider(tokensByProvider)
            .tokensByAgent(tokensByAgent)
            .operationCount(operations.size())
            .build();
    }
}
```

### Token Usage Data Model

```java
@Data
@Builder
public class TokenUsage {
    private int promptTokens;
    private int generationTokens;
    private int totalTokens;
    private String model;
    private String provider;
    private Duration processingTime;
    private double cost; // Provider's cost if available
    
    public static TokenUsage fromChatResponse(ChatResponse response, String provider) {
        ChatResponseMetadata metadata = response.getMetadata();
        Usage usage = metadata.getUsage();
        
        return TokenUsage.builder()
            .promptTokens(usage.getPromptTokens())
            .generationTokens(usage.getGenerationTokens())
            .totalTokens(usage.getTotalTokens())
            .model(metadata.getModel())
            .provider(provider)
            .build();
    }
}
```

## Enhanced Agent Result Processing

### AgentResultProcessor with Cost Integration

```java
@Service
@Transactional
public class AgentResultProcessor {
    
    private final PaperRepository paperRepository;
    private final TokenTrackingService tokenTrackingService;
    private final CreditService creditService;
    private final UserOperationRepository userOperationRepository;
    private final Logger logger = LoggerFactory.getLogger(AgentResultProcessor.class);
    
    /**
     * Process agent results with cost tracking and storage.
     */
    public void processAgentResult(AgentTask task, AgentResult result, TokenUsage tokenUsage) {
        try {
            // Track token usage and costs
            trackOperationCost(task, result, tokenUsage);
            
            // Store results in appropriate paper fields
            storeResultsInPaper(task, result);
            
            // Update paper processing status
            updatePaperStatus(task, result);
            
            logger.info("Processed agent result for task {} with {} tokens", 
                       task.getId(), tokenUsage.getTotalTokens());
            
        } catch (Exception e) {
            logger.error("Failed to process agent result for task {}: {}", task.getId(), e.getMessage(), e);
            throw new AgentResultProcessingException("Failed to process agent result", e);
        }
    }
    
    /**
     * Track operation cost and deduct credits.
     */
    private void trackOperationCost(AgentTask task, AgentResult result, TokenUsage tokenUsage) {
        String operationType = mapAgentToOperationType(task.getAgentId());
        
        // Track token usage (creates UserOperation record)
        tokenTrackingService.trackTokenUsage(
            task.getUserId(),
            operationType,
            task.getAgentId(),
            tokenUsage,
            task.getId()
        );
        
        // Deduct credits from user balance
        int creditCost = tokenTrackingService.calculateTokenBasedCost(operationType, tokenUsage);
        creditService.deductCredits(task.getUserId(), creditCost, operationType, task.getId());
    }
    
    /**
     * Store agent results in appropriate paper JSONB fields.
     */
    private void storeResultsInPaper(AgentTask task, AgentResult result) {
        String paperId = extractPaperIdFromTask(task);
        if (paperId == null) return;
        
        Paper paper = paperRepository.findById(UUID.fromString(paperId))
            .orElseThrow(() -> new EntityNotFoundException("Paper not found: " + paperId));
        
        // Map agent results to paper fields based on agent type
        switch (task.getAgentId()) {
            case "paper-processor":
                storePaperProcessorResults(paper, result);
                break;
            case "content-summarizer":
                storeContentSummarizerResults(paper, result);
                break;
            case "concept-explainer":
                storeConceptExplainerResults(paper, result);
                break;
            case "quality-checker":
                storeQualityCheckerResults(paper, result);
                break;
            case "citation-formatter":
                storeCitationFormatterResults(paper, result);
                break;
            case "metadata-enhancer":
                storeMetadataEnhancerResults(paper, result);
                break;
            case "research-discovery":
                storeResearchDiscoveryResults(paper, result);
                break;
        }
        
        paper.setUpdatedAt(LocalDateTime.now());
        paperRepository.save(paper);
    }
    
    /**
     * Store paper processor results.
     */
    private void storePaperProcessorResults(Paper paper, AgentResult result) {
        if (result.hasData("extractedText")) {
            paper.setTextContent(result.getDataAsString("extractedText"));
        }
        
        if (result.hasData("structure")) {
            JsonNode existingMetadata = paper.getMetadata();
            ObjectNode metadata = existingMetadata != null ? 
                (ObjectNode) existingMetadata : JsonNodeFactory.instance.objectNode();
            metadata.set("structure", result.getDataAsJsonNode("structure"));
            paper.setMetadata(metadata);
        }
        
        if (result.hasData("sections")) {
            JsonNode existingMetadata = paper.getMetadata();
            ObjectNode metadata = existingMetadata != null ? 
                (ObjectNode) existingMetadata : JsonNodeFactory.instance.objectNode();
            metadata.set("sections", result.getDataAsJsonNode("sections"));
            paper.setMetadata(metadata);
        }
    }
    
    /**
     * Store content summarizer results.
     */
    private void storeContentSummarizerResults(Paper paper, AgentResult result) {
        if (result.hasData("briefSummary")) {
            paper.setSummaryBrief(result.getDataAsString("briefSummary"));
        }
        
        if (result.hasData("standardSummary")) {
            paper.setSummaryStandard(result.getDataAsString("standardSummary"));
        }
        
        if (result.hasData("detailedSummary")) {
            paper.setSummaryDetailed(result.getDataAsString("detailedSummary"));
        }
        
        if (result.hasData("keyFindings")) {
            paper.setKeyFindings(result.getDataAsJsonNode("keyFindings"));
        }
    }
    
    /**
     * Store concept explainer results.
     */
    private void storeConceptExplainerResults(Paper paper, AgentResult result) {
        if (result.hasData("glossary")) {
            paper.setGlossary(result.getDataAsJsonNode("glossary"));
        }
        
        if (result.hasData("mainConcepts")) {
            paper.setMainConcepts(result.getDataAsJsonNode("mainConcepts"));
        }
        
        if (result.hasData("topics")) {
            paper.setTopics(result.getDataAsList("topics"));
        }
    }
    
    /**
     * Store quality checker results.
     */
    private void storeQualityCheckerResults(Paper paper, AgentResult result) {
        if (result.hasData("qualityFeedback")) {
            paper.setQualityFeedback(result.getDataAsJsonNode("qualityFeedback"));
        }
        
        if (result.hasData("qualityScore")) {
            paper.setQualityScore(result.getDataAsDouble("qualityScore"));
        }
    }
    
    /**
     * Store citation formatter results.
     */
    private void storeCitationFormatterResults(Paper paper, AgentResult result) {
        if (result.hasData("citations")) {
            paper.setCitations(result.getDataAsJsonNode("citations"));
        }
        
        if (result.hasData("referencesCount")) {
            paper.setReferencesCount(result.getDataAsInteger("referencesCount"));
        }
    }
    
    /**
     * Store metadata enhancer results.
     */
    private void storeMetadataEnhancerResults(Paper paper, AgentResult result) {
        if (result.hasData("crossrefMetadata")) {
            paper.setCrossrefMetadata(result.getDataAsJsonNode("crossrefMetadata"));
            paper.setCrossrefVerified(true);
            paper.setCrossrefLastVerified(LocalDateTime.now());
        }
        
        if (result.hasData("semanticScholarMetadata")) {
            paper.setSemanticScholarMetadata(result.getDataAsJsonNode("semanticScholarMetadata"));
            paper.setSemanticScholarVerified(true);
            paper.setSemanticScholarLastVerified(LocalDateTime.now());
        }
        
        if (result.hasData("doi")) {
            paper.setDoi(result.getDataAsString("doi"));
        }
    }
    
    /**
     * Store research discovery results.
     */
    private void storeResearchDiscoveryResults(Paper paper, AgentResult result) {
        if (result.hasData("researchQuestions")) {
            paper.setResearchQuestions(result.getDataAsJsonNode("researchQuestions"));
        }
        
        if (result.hasData("methodologyDetails")) {
            paper.setMethodologyDetails(result.getDataAsJsonNode("methodologyDetails"));
        }
        
        // Store discovery results in metadata
        if (result.hasData("relatedPapers") || result.hasData("researchTrends")) {
            JsonNode existingMetadata = paper.getMetadata();
            ObjectNode metadata = existingMetadata != null ? 
                (ObjectNode) existingMetadata : JsonNodeFactory.instance.objectNode();
            
            if (result.hasData("relatedPapers")) {
                metadata.set("relatedPapers", result.getDataAsJsonNode("relatedPapers"));
            }
            
            if (result.hasData("researchTrends")) {
                metadata.set("researchTrends", result.getDataAsJsonNode("researchTrends"));
            }
            
            paper.setMetadata(metadata);
        }
    }
    
    /**
     * Update paper processing status.
     */
    private void updatePaperStatus(AgentTask task, AgentResult result) {
        String paperId = extractPaperIdFromTask(task);
        if (paperId == null) return;
        
        Paper paper = paperRepository.findById(UUID.fromString(paperId))
            .orElse(null);
        
        if (paper != null) {
            if (result.isSuccess()) {
                // Update status based on agent completion
                updateProcessingStatusForAgent(paper, task.getAgentId());
            } else {
                paper.setProcessingStatus("FAILED");
                paper.setStatus("ERROR");
            }
            
            paperRepository.save(paper);
        }
    }
    
    /**
     * Map agent types to operation types for cost tracking.
     */
    private String mapAgentToOperationType(String agentId) {
        return switch (agentId) {
            case "paper-processor" -> "PAPER_TEXT_EXTRACTION";
            case "metadata-enhancer" -> "METADATA_ENHANCEMENT";
            case "content-summarizer" -> "CONTENT_SUMMARIZATION";
            case "concept-explainer" -> "CONCEPT_EXPLANATION";
            case "quality-checker" -> "QUALITY_CHECKING";
            case "citation-formatter" -> "CITATION_FORMATTING";
            case "research-discovery" -> "RESEARCH_DISCOVERY";
            default -> "PAPER_ANALYSIS"; // Fallback to existing operation
        };
    }
    
    /**
     * Update processing status based on completed agents.
     */
    private void updateProcessingStatusForAgent(Paper paper, String agentId) {
        String currentStatus = paper.getProcessingStatus();
        
        // Define processing stages
        Set<String> completedStages = parseCompletedStages(currentStatus);
        completedStages.add(agentId);
        
        // Check if all required stages are complete
        if (isFullProcessingComplete(completedStages)) {
            paper.setProcessingStatus("COMPLETED");
            paper.setStatus("PROCESSED");
        } else {
            paper.setProcessingStatus("PROCESSING_" + String.join("_", completedStages));
        }
    }
    
    private Set<String> parseCompletedStages(String status) {
        if (status != null && status.startsWith("PROCESSING_")) {
            String stages = status.substring("PROCESSING_".length());
            return new HashSet<>(Arrays.asList(stages.split("_")));
        }
        return new HashSet<>();
    }
    
    private boolean isFullProcessingComplete(Set<String> completedStages) {
        Set<String> requiredStages = Set.of(
            "paper-processor", "metadata-enhancer", "content-summarizer",
            "concept-explainer", "quality-checker", "citation-formatter"
        );
        return completedStages.containsAll(requiredStages);
    }
}
```

## Cost Monitoring and Analytics

### CostAnalyticsService

```java
@Service
public class CostAnalyticsService {
    
    private final UserOperationRepository userOperationRepository;
    private final CreditTransactionRepository creditTransactionRepository;
    
    /**
     * Get cost analytics for multi-agent operations.
     */
    public MultiAgentCostAnalytics getCostAnalytics(UUID userId, LocalDateTime since) {
        List<UserOperation> operations = userOperationRepository
            .findByUserIdAndCreatedAtAfterAndOperationTypeIn(
                userId, since, getMultiAgentOperationTypes()
            );
        
        Map<String, Integer> costsByOperation = new HashMap<>();
        Map<String, Long> tokensByOperation = new HashMap<>();
        Map<String, Integer> countByOperation = new HashMap<>();
        
        int totalCredits = 0;
        long totalTokens = 0;
        
        for (UserOperation op : operations) {
            String opType = op.getOperationType();
            int credits = op.getCreditCost() != null ? op.getCreditCost() : 0;
            
            costsByOperation.merge(opType, credits, Integer::sum);
            countByOperation.merge(opType, 1, Integer::sum);
            totalCredits += credits;
            
            // Extract token count from metadata
            if (op.getMetadata() != null && op.getMetadata().has("totalTokens")) {
                long tokens = op.getMetadata().get("totalTokens").asLong();
                tokensByOperation.merge(opType, tokens, Long::sum);
                totalTokens += tokens;
            }
        }
        
        return MultiAgentCostAnalytics.builder()
            .userId(userId)
            .period(since)
            .totalCredits(totalCredits)
            .totalTokens(totalTokens)
            .costsByOperation(costsByOperation)
            .tokensByOperation(tokensByOperation)
            .countByOperation(countByOperation)
            .operationCount(operations.size())
            .averageCostPerOperation(operations.isEmpty() ? 0 : totalCredits / operations.size())
            .averageTokensPerOperation(operations.isEmpty() ? 0 : totalTokens / operations.size())
            .build();
    }
    
    private List<String> getMultiAgentOperationTypes() {
        return Arrays.asList(
            "PAPER_TEXT_EXTRACTION",
            "METADATA_ENHANCEMENT", 
            "CONTENT_SUMMARIZATION",
            "CONCEPT_EXPLANATION",
            "QUALITY_CHECKING",
            "CITATION_FORMATTING",
            "RESEARCH_DISCOVERY",
            "FULL_PIPELINE_PROCESSING"
        );
    }
}
```

## Integration Summary

This comprehensive integration ensures that all multi-agent pipeline operations are properly tracked, costed, and their results stored in the existing Answer42 database schema while maintaining full token usage visibility and credit management.

**✅ Completed Database Integration:**
1. **Schema Compliance**: All operation types properly uppercase
2. **Cost Tracking**: 8 new operation types with tiered pricing
3. **Token Management**: Complete token usage tracking and analytics
4. **Results Storage**: Agent results mapped to appropriate paper JSONB fields
5. **Credit System**: Integrated with existing credit management
6. **Processing Status**: Pipeline progress tracking and status updates

The multi-agent pipeline is now fully integrated with Answer42's existing infrastructure and ready for implementation.
